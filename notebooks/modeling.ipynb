{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Union\n",
    "from PIL import Image\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_config (SEED_VALUE=42, package_list=None):\n",
    "\n",
    "    random.seed(SEED_VALUE)\n",
    "    np.random.seed(SEED_VALUE)\n",
    "    torch.manual_seed(SEED_VALUE)\n",
    "\n",
    "    def is_running_in_kaggle():\n",
    "        return \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
    "    \n",
    "    #GPU check\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using CUDA GPU\")\n",
    "\n",
    "\n",
    "        \n",
    "        DEVICE = torch.device(\"cuda\")\n",
    "        print(\"Devide: \",  DEVICE)\n",
    "        GPU_AVAILABLE = True\n",
    "\n",
    "        torch.cuda.manual_seed_all(SEED_VALUE)\n",
    "        torch.cuda.manual_seed(SEED_VALUE)\n",
    "\n",
    "        torch.backends.cudnn.enabled = True       # Provides highly optimized primitives for DL operations.\n",
    "        torch.backends.cudnn.deterministic = True # Insures deterministic even when above cudnn is enabled.\n",
    "        torch.backends.cudnn.benchmark = False    # Setting to True can cause non-deterministic behavior.\n",
    "\n",
    "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        print('Using Apple Silicon GPU')\n",
    "\n",
    "        # Set the device to the Apple Silicon GPU Metal Performance Shader (MPS).\n",
    "        DEVICE = torch.device(\"mps\")\n",
    "        print(\"Device: \", DEVICE)\n",
    "        # Environment variable that allows PyTorch to fall back to CPU execution\n",
    "        # when encountering operations that are not currently supported by MPS.\n",
    "        os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "        GPU_AVAILABLE = True\n",
    "\n",
    "        torch.mps.manual_seed(SEED_VALUE)\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    else:\n",
    "        print('Using CPU')\n",
    "        DEVICE = torch.device('cpu')\n",
    "        print(\"Device: \", DEVICE)\n",
    "        GPU_AVAILABLE = False\n",
    "\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    return str(DEVICE), GPU_AVAILABLE\n",
    "\n",
    "DEVICE, GPU_AVAILABLE = system_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entorn variables\n",
    "RANDOM_SEED = 42\n",
    "DATA_DIR = os.path.join(\"..\", \"data\")\n",
    "LABEL_WEIGHTS = {\n",
    "    \"Dry_Green_g\": 0.1,\n",
    "    \"Dry_Dead_g\": 0.1,\n",
    "    \"Dry_Clover_g\": 0.1,\n",
    "    \"GDM_g\": 0.2,\n",
    "    \"Dry_Total_g\": 0.5\n",
    "}\n",
    "N_SPLITS = 3\n",
    "TARGET_NAMES= list(LABEL_WEIGHTS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement competition loss function \n",
    "def globally_weighted_r_squared(y_true: torch.tensor, y_pred: torch.tensor, target_class: list[str], eps: float = 1e-12) -> torch.tensor:\n",
    "    y_true = y_true.view(-1).float()\n",
    "    y_pred = y_pred.view(-1).float()\n",
    "\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"Shapes must match. Got {y_true.shape} vs {y_pred.shape}.\")\n",
    "\n",
    "    weights = torch.tensor([LABEL_WEIGHTS[cls] for cls in target_class], device=y_true.device, dtype=y_true.dtype)\n",
    "\n",
    "    y_bar = torch.sum(weights * y_true)/weights.sum()\n",
    "    ss_res = torch.sum(weights * (y_true - y_pred) ** 2)\n",
    "    ss_tot = torch.sum(weights * (y_true - y_bar) ** 2) + eps\n",
    "\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "    return r_squared\n",
    "\n",
    "# Plotting and diagnostics\n",
    "def plot_training_curves(\n",
    "    train_losses, val_losses,\n",
    "    train_metric, val_metric,\n",
    "    metric_name=\"R²\"\n",
    "):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    # --- LOSS ---\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss (MSE)\")\n",
    "    plt.title(\"Training vs Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- METRIC ---\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(epochs, train_metric, label=f\"Train {metric_name}\")\n",
    "    plt.plot(epochs, val_metric, label=f\"Val {metric_name}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title(f\"Training vs Validation {metric_name}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#Image Preprocessing\n",
    "\n",
    "# def resize_split(\n",
    "#         src_dir:str,\n",
    "#         dst_dir:str,\n",
    "#         size_hw=(256, 256),\n",
    "#         verbose:bool=True\n",
    "#         ):\n",
    "#     \"\"\"\n",
    "#     Resize all images in src_dir and save into dst_dir.\n",
    "#     \"\"\"\n",
    "#     os.makedirs(dst_dir, exist_ok=True)\n",
    "#     H, W = size_hw\n",
    "#     files = [f for f in os.listdir(src_dir) if not f.startswith('.')]\n",
    "\n",
    "#     n_ok, n_fail = 0, 0\n",
    "\n",
    "#     for file in tqdm(files, disable=not verbose):\n",
    "#         in_path = os.path.join(src_dir, file)\n",
    "#         out_path = os.path.join(dst_dir, file)\n",
    "\n",
    "#         img = cv2.imread(in_path, cv2.IMREAD_COLOR)\n",
    "#         if img is None:\n",
    "#             n_fail += 1\n",
    "#             continue\n",
    "#         resized = cv2.resize(img, (W, H), interpolation=cv2.INTER_AREA)\n",
    "#         ok = cv2.imwrite(out_path, resized)\n",
    "#         if ok:\n",
    "#             n_ok += 1\n",
    "#         else:\n",
    "#             n_fail += 1\n",
    "#     print(f\"✅ Done. OK: {n_ok} | Failed: {n_fail}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAW_DIR = os.path.join(\"..\", \"data\", \"raw\")\n",
    "# RESIZED_DIR = os.path.join(\"..\", \"data\", \"resized\")\n",
    "\n",
    "# resize_split(\n",
    "#     src_dir=os.path.join(RAW_DIR, \"train\"),\n",
    "#     dst_dir=os.path.join(RESIZED_DIR, \"train\"),\n",
    "#     size_hw=(128, 64),\n",
    "# )\n",
    "\n",
    "# resize_split(\n",
    "#     src_dir=os.path.join(RAW_DIR, \"test\"),\n",
    "#     dst_dir=os.path.join(RESIZED_DIR, \"test\"),\n",
    "#     size_hw=(128, 64),\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: implement robust validation set\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"raw\", \"train.csv\"))\n",
    "train_df[\"id\"] = train_df[\"image_path\"].apply(lambda row: row.replace(\"train/\", \"\").replace(\".jpg\", \"\"))\n",
    "train_df_ids = train_df.groupby(\"id\", as_index=False).agg(\n",
    "    Pre_GSHH_NDVI = (\"Pre_GSHH_NDVI\", \"first\"),\n",
    "    Height_Ave_cm = (\"Height_Ave_cm\", \"first\"),\n",
    ")\n",
    "\n",
    "train_df_ids[\"ndvi_bin\"] = pd.qcut(train_df_ids[\"Pre_GSHH_NDVI\"], q=3, duplicates=\"drop\")\n",
    "train_df_ids[\"h_bin\"] = pd.qcut(train_df_ids[\"Height_Ave_cm\"], q=3, duplicates=\"drop\")\n",
    "\n",
    "train_df_ids[\"stratify_group\"] = train_df_ids[\"ndvi_bin\"].astype(str) + \"_\" + train_df_ids[\"h_bin\"].astype(str)\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state= RANDOM_SEED)\n",
    "\n",
    "train_df_ids[\"fold\"] = -1\n",
    "\n",
    "X = train_df_ids[[\"Pre_GSHH_NDVI\", \"Height_Ave_cm\"]]\n",
    "y = train_df_ids[\"stratify_group\"]\n",
    "groups = train_df_ids[\"id\"]\n",
    "\n",
    "for fold, (_, val_idx) in enumerate(sgkf.split(X, y, groups=groups)):\n",
    "    train_df_ids.loc[val_idx, \"fold\"] = fold\n",
    "\n",
    "train_df = train_df.merge(train_df_ids[[\"id\", \"fold\"]], on=\"id\", how=\"left\")\n",
    "assert train_df[\"fold\"].isna().sum() == 0\n",
    "\n",
    "check = train_df_ids.groupby(\"fold\")[[\"Pre_GSHH_NDVI\", \"Height_Ave_cm\"]].describe()\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0 #Choose validation fold\n",
    "\n",
    "train_df_fold = train_df[train_df[\"fold\"] != FOLD].reset_index(drop=True)\n",
    "val_df_fold = train_df[train_df[\"fold\"] == FOLD].reset_index(drop=True)\n",
    "\n",
    "assert set(train_df_fold[\"id\"]).isdisjoint(set(val_df_fold[\"id\"]))\n",
    "\n",
    "images_df_train = (\n",
    "    train_df_fold[[\"id\", \"image_path\"]]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "def build_targets(df):\n",
    "    images = df[[\"id\", \"image_path\"]].drop_duplicates()\n",
    "    targets = df.pivot(index=\"id\", columns=\"target_name\", values=\"target\").reset_index()\n",
    "    target_df = images.merge(targets, on=\"id\") \n",
    "\n",
    "    return target_df\n",
    "\n",
    "train_targets = build_targets(train_df_fold)\n",
    "val_targets = build_targets(val_df_fold)\n",
    "\n",
    "train_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets[TARGET_NAMES] = train_targets[TARGET_NAMES].apply(pd.to_numeric, errors=\"coerce\")\n",
    "val_targets[TARGET_NAMES]   = val_targets[TARGET_NAMES].apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiomassDataset(Dataset):\n",
    "    def __init__(self, df, image_root, transform=None):\n",
    "        self.df = df\n",
    "        self.image_root = image_root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        img_path = os.path.join(self.image_root, row[\"image_path\"])\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(img_path)\n",
    "        image = image[:, :, ::-1] #Take all channels\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        y =  torch.from_numpy(\n",
    "            row[TARGET_NAMES].astype(\"float32\").values,\n",
    "        )\n",
    "        return image, y\n",
    "\n",
    "class BiomassTestDataset(Dataset):\n",
    "    def __init__(self, df_unique, image_root, transform=None):\n",
    "        self.df = df_unique.reset_index(drop=True)\n",
    "        self.image_root = image_root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.image_root, row[\"image_path\"])\n",
    "\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(img_path)\n",
    "\n",
    "        green = image[:, :, ::-1]               # (H,W,3)\n",
    "        pil_img = Image.fromarray(green)     # PIL\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(pil_img)      # tensor (1,H,W)\n",
    "        else:\n",
    "            x = transforms.ToTensor()(pil_img)\n",
    "\n",
    "        return x, row[\"image_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TARGET_NAMES)\n",
    "print([c for c in TARGET_NAMES if c not in train_targets.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(256),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.RandomRotation(degrees=15),  \n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.02)], p=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = BiomassDataset(\n",
    "    train_targets, \n",
    "    image_root=os.path.join(DATA_DIR, \"raw\"),\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "val_ds = BiomassDataset(\n",
    "    val_targets,\n",
    "    image_root=os.path.join(DATA_DIR, \"raw\"),\n",
    "    transform=val_transforms\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_preds_3_to_5(pred3: torch.Tensor) -> torch.Tensor:\n",
    "    # pred3: (B, 3) -> [Green, Dead, Clover]\n",
    "    green = pred3[:, 0:1]\n",
    "    dead = pred3[:, 1:2]\n",
    "    clover = pred3[:, 2:3]\n",
    "\n",
    "    gdm = green + clover\n",
    "    total = green + dead + clover\n",
    "    pred5 = torch.cat([green, dead, clover, gdm, total], dim=1)  # (B, 5)\n",
    "    return pred5\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.n_outputs = len(TARGET_NAMES)\n",
    "\n",
    "        self.backbone = nn.Sequential( #in 256,256) \n",
    "            nn.Conv2d(3, 6, kernel_size=5), #After conv ((256+2p-k)/s)+1 p =0 y s =1 252 shape after = (252, 252, 6)\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2), # (126, 126, 6)\n",
    "\n",
    "            nn.Conv2d(6, 16, kernel_size=5), # (122, 122, 16)\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2), # (61, 61)\n",
    "        )\n",
    "        self.head = self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 61 * 61, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, self.n_outputs-2),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "def train(\n",
    "    DEVICE: torch.device,\n",
    "    model: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    train_loader: DataLoader,\n",
    "    epoch_index: int\n",
    ") -> Tuple[float, float]:\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    step_loss = 0.0\n",
    "    n_samples = 0\n",
    "\n",
    "    all_y_true, all_y_pred, all_target_class = [], [], []\n",
    "\n",
    "    criterion = nn.SmoothL1Loss(beta=5.0)\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        targets = targets.to(DEVICE).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs_3 = model(images)\n",
    "        loss = criterion(outputs_3, targets[:, :3])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "        step_loss += loss.item() * batch_size\n",
    "        n_samples += batch_size\n",
    "\n",
    "        outputs_5 = expand_preds_3_to_5(outputs_3)\n",
    "\n",
    "        B = targets.size(0)\n",
    "        all_y_true.append(targets.detach().cpu().reshape(-1))\n",
    "        all_y_pred.append(outputs_5.detach().cpu().reshape(-1))\n",
    "        all_target_class.extend(TARGET_NAMES * B)\n",
    "\n",
    "    epoch_loss = step_loss / max(n_samples,1)\n",
    "    y_true = torch.cat(all_y_true)\n",
    "    y_pred = torch.cat(all_y_pred)\n",
    "    epoch_r2 = globally_weighted_r_squared(y_true, y_pred, all_target_class).item()\n",
    "\n",
    "    print(f\"Epoch {epoch_index}: Train loss={epoch_loss:.4f}, R^2={epoch_r2:.4f}\")\n",
    "    return epoch_loss, epoch_r2\n",
    "\n",
    "\n",
    "def validate(DEVICE: torch.device,\n",
    "             model: nn.Module,\n",
    "             val_loader: DataLoader,\n",
    "             epoch_index: int\n",
    "            ) -> Tuple[float, float]:\n",
    "    \n",
    "    model.eval() #Set model to evaluation mode\n",
    "\n",
    "    step_loss = 0.0\n",
    "    n_samples = 0\n",
    "\n",
    "    criterion = nn.SmoothL1Loss(beta=5.0)\n",
    "\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    all_target_class = []\n",
    "\n",
    "    for data, target in val_loader:\n",
    "        data = data.to(DEVICE)\n",
    "        target = target.to(DEVICE).float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs_3 = model(data)\n",
    "            loss = criterion(outputs_3, target[:, :3])\n",
    "\n",
    "        batch_size = data.size(0)\n",
    "        step_loss += loss.item() * batch_size\n",
    "        n_samples += batch_size \n",
    "\n",
    "        outputs_5 = expand_preds_3_to_5(outputs_3)\n",
    "        B = target.size(0)\n",
    "        all_y_true.append(target.detach().cpu().reshape(-1))\n",
    "        all_y_pred.append(outputs_5.detach().cpu().reshape(-1))\n",
    "        all_target_class.extend(TARGET_NAMES * B)\n",
    "    \n",
    "    val_loss = step_loss/max(n_samples,1)\n",
    "    y_true = torch.cat(all_y_true)\n",
    "    y_pred = torch.cat(all_y_pred)\n",
    "    val_r2 = globally_weighted_r_squared(y_true, y_pred, all_target_class).item()\n",
    "    print(f\"Epoch {epoch_index}: Val loss={val_loss:.4f}, R^2={val_r2:.4f}\")\n",
    "    return val_loss, val_r2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_loader))\n",
    "print(xb.shape, yb.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regressor()\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 200\n",
    "\n",
    "train_losses, train_comp_metric = [], []\n",
    "val_losses, val_comp_metric = [], []\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer=optimizer, mode=\"max\", factor=0.5, patience=10, min_lr = 1e-6\n",
    ")\n",
    "\n",
    "best_val_r2 = -np.inf\n",
    "best_epoch = -1\n",
    "best_path = \"best_model.pt\"\n",
    "\n",
    "patience = 20\n",
    "wait = 0\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    train_loss, train_r2 = train(DEVICE, model, optimizer, train_loader, epoch)\n",
    "    val_loss, val_r2     = validate(DEVICE, model, val_loader, epoch)\n",
    "    scheduler.step(val_r2)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_comp_metric.append(train_r2)\n",
    "    val_losses.append(val_loss)\n",
    "    val_comp_metric.append(val_r2)\n",
    "\n",
    "    if val_r2 > best_val_r2:\n",
    "        wait = 0\n",
    "        best_val_r2 = val_r2\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "        print(f\"  + New best model saved at epoch {best_epoch} with Val R^2={best_val_r2:.4f}\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}. Best epoch was {best_epoch} with Val R^2={best_val_r2:.4f}\")\n",
    "            break\n",
    "\n",
    "    print(\"Best Epoch:\", best_epoch, \"Best Val R^2:\", best_val_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(\n",
    "    train_losses=train_losses,\n",
    "    val_losses=val_losses,\n",
    "    train_metric=train_comp_metric,\n",
    "    val_metric=val_comp_metric,\n",
    "    metric_name=\"Weighted R²\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = Regressor().to(DEVICE)\n",
    "best_model.load_state_dict(torch.load(best_path, map_location=DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(\n",
    "    model: torch.nn.Module,\n",
    "    device: torch.device,\n",
    "    test_df_long: pd.DataFrame,     # columns: sample_id, image_path, target_name\n",
    "    image_root: str,                # carpeta donde están las imágenes resized (ej ../data/resized)\n",
    "    transform,\n",
    "    out_csv_path: str = \"submission.csv\",\n",
    "    batch_size: int = 32,\n",
    "):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # 1) una fila por imagen\n",
    "    df_unique = test_df_long[[\"image_path\"]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # 2) dataset + loader\n",
    "    test_ds = BiomassTestDataset(df_unique, image_root=image_root, transform=transform)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    # 3) predecir (guardamos por image_path)\n",
    "    preds_map = {}  # image_path -> np.array shape (5,)\n",
    "    with torch.no_grad():\n",
    "        for xb, paths in test_loader:\n",
    "            xb = xb.to(device)\n",
    "            out = model(xb)  # (B,5)\n",
    "            outputs_3 = torch.clamp(outputs_3, min=0)\n",
    "            out_5 = expand_preds_3_to_5(out)\n",
    "            out_5 = out_5.detach().cpu().numpy()\n",
    "\n",
    "            for p, vec in zip(paths, out_5):\n",
    "                preds_map[p] = vec\n",
    "\n",
    "    # 4) construir submission en formato long\n",
    "    #    Cada fila del test_df_long corresponde a un sample_id y un target_name\n",
    "    target_idx = {name: i for i, name in enumerate(TARGET_NAMES)}\n",
    "\n",
    "    preds = []\n",
    "    for _, row in test_df_long.iterrows():\n",
    "        img_path = row[\"image_path\"]\n",
    "        tname = row[\"target_name\"]\n",
    "        vec = preds_map[img_path]\n",
    "        preds.append(vec[target_idx[tname]])\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"sample_id\": test_df_long[\"sample_id\"].values,\n",
    "        \"target\": np.array(preds, dtype=np.float32),\n",
    "    })\n",
    "\n",
    "    submission.to_csv(out_csv_path, index=False)\n",
    "    print(f\"✅ Saved: {out_csv_path} | rows={len(submission)}\")\n",
    "    return submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_long = pd.read_csv(os.path.join(DATA_DIR, \"raw\", \"test.csv\"))\n",
    "\n",
    "submission_df = make_submission(\n",
    "    model=best_model,\n",
    "    device=DEVICE,\n",
    "    test_df_long=test_df_long,\n",
    "    image_root=os.path.join(\"..\", \"data\", \"resized\"),\n",
    "    transform=val_transforms,\n",
    "    out_csv_path=\"submission.csv\",\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
